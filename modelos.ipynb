{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", tf.config.list_physical_devices())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. No outlier treatment\n",
    "Modelos entrenados sin tratamiento de outliers, hay dos casos:\n",
    "- Datos normalizados entre 0 y 1\n",
    "- Datos normalizados entre -1 y 1\n",
    "\n",
    "Las imagenes en la carpeta plots se identifican de la siguiente forma:\n",
    "\n",
    "{normalización}\\_{variable}\\_{neuronas}\\_{ventana temporal}\\_{epochs}ep_{batch size}bs.png\n",
    "\n",
    "Por ejemplo: **01_T_64_24_15ep_32bs.png**\n",
    "- Los datos son normalizados entre 0 y 1. \n",
    "- La variable que muestra la grafica es la Temperatura (T).\n",
    "- La capa LSTM tiene 64 neuronas.\n",
    "- La ventana temporal es de 24 (24 datos previos al instante predicho, cada una de estas 24 representa una medición cada 30min)\n",
    "- Entrenado durante 15 epochs\n",
    "- Batch size de 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 2s 3ms/step\n",
      "546/546 [==============================] - 2s 3ms/step\n",
      "545/545 [==============================] - 3s 5ms/step\n",
      "547/547 [==============================] - 3s 4ms/step\n",
      "546/546 [==============================] - 2s 4ms/step\n",
      "545/545 [==============================] - 5s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "station = 'C6.zip'\n",
    "\n",
    "paths = [f'data/norm_data_01/{station}', f'data/norm_data_11/{station}']\n",
    "input_width = [24, 48, 96]\n",
    "neurons = [64]\n",
    "\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path, compression='zip', header=0, sep=',')\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df = df.astype({'T': 'float', 'HR': 'float', 'P': 'float', 'u2': 'float', 'v2': 'float', 'u6': 'float', 'v6': 'float', 'u10': 'float', 'v10': 'float', 'altitud': 'float', 'latitud': 'float', 'longitud': 'float'})\n",
    "    \n",
    "    min_maxs = json.load(open('data/min_maxs.json', 'r'))\n",
    "\n",
    "    df['day'] = df['date'].dt.dayofyear / 365\n",
    "    df['time'] = df['date'].dt.hour / 24\n",
    "\n",
    "    df = df[['T', 'HR', 'P', 'u10', 'v10', 'day', 'time', 'date']]\n",
    "    cols = ['T', 'HR', 'P', 'u10', 'v10']\n",
    "    for width in input_width:\n",
    "        prediction_width = 1\n",
    "\n",
    "        df_train = df[df['date'] < '2019-01-01']\n",
    "        df_test = df[df['date'] >= '2019-01-01']\n",
    "\n",
    "        train_X = []\n",
    "        train_Y = []\n",
    "\n",
    "        for i in range(width, len(df_train) - prediction_width + 1):\n",
    "            train_X.append(df_train.iloc[i - width:i][cols].values)\n",
    "            train_Y.append(df_train.iloc[i:i + prediction_width][['T', 'u10', 'v10']].values)\n",
    "\n",
    "        test_X = []\n",
    "        test_Y = []\n",
    "\n",
    "        for i in range(width, len(df_test) - prediction_width + 1):\n",
    "            test_X.append(df_test.iloc[i - width:i][cols].values)\n",
    "            test_Y.append(df_test.iloc[i:i + prediction_width][['T', 'u10', 'v10']].values)\n",
    "\n",
    "        train_X = np.array(train_X)\n",
    "        train_Y = np.array(train_Y)\n",
    "\n",
    "        test_X = np.array(test_X)\n",
    "        test_Y = np.array(test_Y)\n",
    "\n",
    "        if path.split('/')[1].split('_')[-1][0] == '1':\n",
    "            test_Y[:, 0, 0] = (test_Y[:, 0, 0] + 1) * ((min_maxs['T'][1] - min_maxs['T'][0]) * 0.5) + min_maxs['T'][0]\n",
    "            test_Y[:, 0, 1] = (test_Y[:, 0, 1] + 1) * ((min_maxs['u10'][1] - min_maxs['u10'][0]) * 0.5) + min_maxs['u10'][0]\n",
    "            test_Y[:, 0, 2] = (test_Y[:, 0, 2] + 1) * ((min_maxs['v10'][1] - min_maxs['v10'][0]) * 0.5) + min_maxs['v10'][0]\n",
    "        else:\n",
    "            test_Y[:, 0, 0] = test_Y[:, 0, 0] * (min_maxs['T'][1] - min_maxs['T'][0]) + min_maxs['T'][0]\n",
    "            test_Y[:, 0, 1] = test_Y[:, 0, 1] * (min_maxs['u10'][1] - min_maxs['u10'][0]) + min_maxs['u10'][0]\n",
    "            test_Y[:, 0, 2] = test_Y[:, 0, 2] * (min_maxs['v10'][1] - min_maxs['v10'][0]) + min_maxs['v10'][0]\n",
    "\n",
    "        for n in neurons:\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(n, activation='tanh', input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(units=3, activation='linear'))\n",
    "\n",
    "            model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "            print(\"Training model with input width: \", width, \" and \", n, \" neurons\")\n",
    "            with tf.device('/device:GPU:0'):\n",
    "                history = model.fit(train_X, train_Y, epochs=15, batch_size=32, validation_split=0.1, verbose=1, shuffle=False)\n",
    "            model.save(f'models/lstm_{path.split(\"_\")[-1].split(\"/\")[0]}_{n}_{width}_15epochs_32bs.h5')\n",
    "\n",
    "            y_pred = model.predict(test_X)\n",
    "            for idx, column in enumerate(['T', 'u10', 'v10']):\n",
    "                plt.figure(figsize=(10, 6))\n",
    "\n",
    "                if path.split('/')[1].split('_')[-1][0] == '1':\n",
    "                    y_pred[:, idx] = (y_pred[:, idx] + 1) * ((min_maxs[column][1] - min_maxs[column][0]) * 0.5) + min_maxs[column][0]\n",
    "                else:\n",
    "                    y_pred[:, idx] = y_pred[:, idx] * (min_maxs[column][1] - min_maxs[column][0]) + min_maxs[column][0]\n",
    "                \n",
    "                plt.plot(test_Y[:1000, 0, idx], label='Real')\n",
    "                plt.plot(y_pred[:1000, idx], label='Pred')\n",
    "                \n",
    "                rmse = np.sqrt(np.mean(np.power((test_Y[:, 0, idx] - y_pred[:, idx]), 2)))\n",
    "                plt.legend()\n",
    "                plt.title(f'{path.split(\"/\")[1].split(\"_\")[-1]}_{n}_{width}_15epochs_32bs{column}, RMSE: {rmse:.6f}')\n",
    "                plt.savefig(f'plots/{path.split(\"/\")[1].split(\"_\")[-1]}_{column}_{n}_{width}_15ep_32bs.png')\n",
    "                plt.clf()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Treated outliers\n",
    "\n",
    "Modelos entrenados usando IQR como tratamiento de outliers, hay dos casos:\n",
    "- Datos normalizados entre 0 y 1\n",
    "- Datos normalizados entre -1 y 1\n",
    "\n",
    "Las imagenes en la carpeta plots se identifican de la siguiente forma:\n",
    "\n",
    "{normalización}\\_{variable}\\_{neuronas}\\_{ventana temporal}\\_{epochs}ep_{batch size}bs.png\n",
    "\n",
    "Por ejemplo: **o01_T_64_24_15ep_32bs.png**\n",
    "- Los datos son normalizados entre 0 y 1, la letra o indica que se han tratado outliers. \n",
    "- La variable que muestra la grafica es la Temperatura (T).\n",
    "- La capa LSTM tiene 64 neuronas.\n",
    "- La ventana temporal es de 24 (24 datos previos al instante predicho, cada una de estas 24 representa una medición cada 30min)\n",
    "- Entrenado durante 15 epochs\n",
    "- Batch size de 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/547 [==============================] - 2s 4ms/step\n",
      "546/546 [==============================] - 2s 3ms/step\n",
      "545/545 [==============================] - 3s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "station = 'C6.zip'\n",
    "\n",
    "paths = [f'data/norm_data_o01/{station}']#, f'data/norm_data_o11/{station}'\n",
    "\n",
    "input_width = [24, 48, 96]\n",
    "neurons = [64]\n",
    "\n",
    "for path in paths:\n",
    "    df = pd.read_csv(path, compression='zip', header=0, sep=',')\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d %H:%M:%S')\n",
    "    df = df.astype({'T': 'float', 'HR': 'float', 'P': 'float', 'u2': 'float', 'v2': 'float', 'u6': 'float', 'v6': 'float', 'u10': 'float', 'v10': 'float', 'altitud': 'float', 'latitud': 'float', 'longitud': 'float'})\n",
    "    \n",
    "    min_maxs = json.load(open('data/quantiles.json', 'r'))\n",
    "\n",
    "    df['day'] = df['date'].dt.dayofyear / 365\n",
    "    df['time'] = df['date'].dt.hour / 24\n",
    "\n",
    "    df = df[['T', 'HR', 'P', 'u10', 'v10', 'day', 'time', 'date']]\n",
    "    cols = ['T', 'HR', 'P', 'u10', 'v10']\n",
    "    for width in input_width:\n",
    "        prediction_width = 1\n",
    "\n",
    "        df_train = df[df['date'] < '2019-01-01']\n",
    "        df_test = df[df['date'] >= '2019-01-01']\n",
    "\n",
    "        train_X = []\n",
    "        train_Y = []\n",
    "\n",
    "        for i in range(width, len(df_train) - prediction_width + 1):\n",
    "            train_X.append(df_train.iloc[i - width:i][cols].values)\n",
    "            train_Y.append(df_train.iloc[i:i + prediction_width][['T', 'u10', 'v10']].values)\n",
    "\n",
    "        test_X = []\n",
    "        test_Y = []\n",
    "\n",
    "        for i in range(width, len(df_test) - prediction_width + 1):\n",
    "            test_X.append(df_test.iloc[i - width:i][cols].values)\n",
    "            test_Y.append(df_test.iloc[i:i + prediction_width][['T', 'u10', 'v10']].values)\n",
    "\n",
    "        train_X = np.array(train_X)\n",
    "        train_Y = np.array(train_Y)\n",
    "\n",
    "        test_X = np.array(test_X)\n",
    "        test_Y = np.array(test_Y)\n",
    "\n",
    "        if path.split('/')[1].split('_')[-1][1] == '1':\n",
    "            test_Y[:, 0, 0] = (test_Y[:, 0, 0] + 1) * ((min_maxs['T'][1] - min_maxs['T'][0]) * 0.5) + min_maxs['T'][0]\n",
    "            test_Y[:, 0, 1] = (test_Y[:, 0, 1] + 1) * ((min_maxs['u10'][1] - min_maxs['u10'][0]) * 0.5) + min_maxs['u10'][0]\n",
    "            test_Y[:, 0, 2] = (test_Y[:, 0, 2] + 1) * ((min_maxs['v10'][1] - min_maxs['v10'][0]) * 0.5) + min_maxs['v10'][0]\n",
    "        else:\n",
    "            test_Y[:, 0, 0] = test_Y[:, 0, 0] * (min_maxs['T'][1] - min_maxs['T'][0]) + min_maxs['T'][0]\n",
    "            test_Y[:, 0, 1] = test_Y[:, 0, 1] * (min_maxs['u10'][1] - min_maxs['u10'][0]) + min_maxs['u10'][0]\n",
    "            test_Y[:, 0, 2] = test_Y[:, 0, 2] * (min_maxs['v10'][1] - min_maxs['v10'][0]) + min_maxs['v10'][0]\n",
    "\n",
    "        for n in neurons:\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(n, activation='tanh', input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(units=3, activation='linear'))\n",
    "\n",
    "            model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "            print(\"Training model with input width: \", width, \" and \", n, \" neurons\")\n",
    "            with tf.device('/device:GPU:0'):\n",
    "                history = model.fit(train_X, train_Y, epochs=15, batch_size=32, validation_split=0.1, verbose=1, shuffle=False)\n",
    "            model.save(f'models/lstm_{path.split(\"_\")[-1].split(\"/\")[0]}_{n}_{width}_15epochs_32bs.h5')\n",
    "            \n",
    "            y_pred = model.predict(test_X)\n",
    "            for idx, column in enumerate(['T', 'u10', 'v10']):\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                if path.split('/')[1].split('_')[-1][1] == '1':\n",
    "                    y_pred[:, idx] = (y_pred[:, idx] + 1) * ((min_maxs[column][1] - min_maxs[column][0]) * 0.5) + min_maxs[column][0]\n",
    "                else:\n",
    "                    y_pred[:, idx] = y_pred[:, idx] * (min_maxs[column][1] - min_maxs[column][0]) + min_maxs[column][0]\n",
    "                \n",
    "                plt.plot(test_Y[:1000, 0, idx], label='Real')\n",
    "                plt.plot(y_pred[:1000, idx], label='Pred')\n",
    "                \n",
    "                rmse = np.sqrt(np.mean(np.power((test_Y[:, 0, idx] - y_pred[:, idx]), 2)))\n",
    "                plt.legend()\n",
    "                plt.title(f'{path.split(\"/\")[1].split(\"_\")[-1]}_{n}_{width}_15epochs_32bs_{column}, RMSE: {rmse:.6f}')\n",
    "                plt.savefig(f'plots/{path.split(\"/\")[1].split(\"_\")[-1]}_{column}_{n}_{width}_15ep_32bs.png')\n",
    "                plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
